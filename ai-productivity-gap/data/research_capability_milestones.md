# Research Notes: AI Model & Tool Capability Milestones (Mid-2023 to Early 2026)

**Research date:** February 2026

---

## Timeline

| Date | Model/Tool | Provider | Capability Unlocked | Plain-Language Description |
|------|-----------|----------|--------------------|-----------------------------|
| **Mar 2023** | GPT-4 | OpenAI | Scored 90th percentile on the bar exam; 93rd percentile on SAT reading | First AI to pass professional exams at expert human levels. You could hand it a law school exam and it would outperform 90% of test-takers. |
| **Mar 2023** | ChatGPT Plugins | OpenAI | Third-party integrations (Expedia, Instacart, OpenTable, etc.) | ChatGPT stopped being a closed chatbot and became a platform -- it could browse the web, book restaurants, order groceries, and connect to business tools. |
| **Jul 2023** | Code Interpreter | OpenAI | Sandboxed Python execution inside ChatGPT; upload files, run analysis, generate charts | Turned ChatGPT into a personal data analyst. Upload a spreadsheet and it writes code, runs it, and gives you charts -- no coding required. |
| **Sep 2023** | GPT-4V (Vision) | OpenAI | Image understanding: analyze photos, charts, documents, screenshots | AI gained "eyes." You could show it a photo of your fridge and ask for recipe ideas, or upload a chart and ask it to explain the trend. |
| **Nov 2023** | GPT-4 Turbo | OpenAI | 128K context window (300+ pages); cheaper pricing; knowledge cutoff extended | Could process the equivalent of an entire novel in one prompt. Dramatically cheaper, making GPT-4-class intelligence accessible to more developers. |
| **Dec 2023** | Gemini 1.0 (Ultra/Pro/Nano) | Google | Three-tier model family; outperformed GPT-4 on 30 of 32 academic benchmarks | Google's answer to GPT-4. First multimodal model from Google designed from the ground up for text, image, and audio understanding. |
| **Feb 2024** | Gemini 1.5 Pro (preview) | Google | 1 million token context window (1 hour of video, 700K words) | Could process an entire codebase, a full-length movie, or hundreds of documents in a single prompt -- 8x larger than any competitor at the time. |
| **Mar 2024** | Claude 3 (Opus/Sonnet/Haiku) | Anthropic | Vision capabilities; near-human performance on graduate-level reasoning (GPQA); 200K context | First Claude model family to see images and process visual information. Opus matched or beat GPT-4 across most benchmarks, establishing Anthropic as a true competitor. |
| **Mar 2024** | Devin | Cognition Labs | First "AI software engineer"; autonomous multi-step coding (13.86% on SWE-bench unassisted) | Went viral as the "first AI software engineer" -- it could plan, write, debug, and deploy code autonomously, handling entire GitHub issues end-to-end. |
| **May 2024** | GPT-4o | OpenAI | Real-time multimodal conversation (text, audio, vision); 320ms voice response time | AI that could see, hear, and talk back in real time. Voice responses at human conversation speed. The live demo showed it reading emotions, translating live speech, and tutoring through a camera. |
| **May 2024** | AlphaFold 3 | Google DeepMind | Predicts structures of proteins with DNA, RNA, ligands, and ions | Extended AlphaFold's Nobel Prize-winning protein structure prediction to virtually all of molecular biology. Researchers use it to design new drugs and understand diseases. |
| **Jun 2024** | Claude 3.5 Sonnet + Artifacts | Anthropic | Mid-tier model outperformed flagship Opus; real-time code preview in-browser | The moment the "smaller, cheaper model beats the flagship" pattern began. Plus, Artifacts let you see and interact with code output live -- like a built-in web IDE. |
| **Sep 2024** | OpenAI o1 (preview) | OpenAI | Chain-of-thought reasoning; PhD-level performance on physics, chemistry, biology benchmarks | First "thinking" model that pauses to reason step-by-step before answering. Scored at PhD level on science benchmarks. Introduced a fundamentally new paradigm: spending more compute at inference time. |
| **Oct 2024** | Claude 3.5 Sonnet (upgraded) + Computer Use | Anthropic | Desktop automation -- cursor movement, clicking, typing; 49% on SWE-bench (SOTA) | First frontier AI model to autonomously control a computer desktop. It could move the mouse, click buttons, and type -- operating software the way a human does. Also became the best coding model at the time. |
| **Oct 2024** | Nobel Prize for AlphaFold | Google DeepMind | 2024 Nobel Prize in Chemistry for protein structure prediction | First time an AI system's creators won a Nobel Prize for the system's scientific contributions. Validated AI as a tool for genuine scientific discovery. |
| **Nov 2024** | Model Context Protocol (MCP) | Anthropic | Open standard for connecting AI models to external tools and data sources | Created a "USB-C for AI" -- a universal plug that lets any AI model connect to any tool or data source. Adopted by OpenAI, Google, and the broader ecosystem within months. |
| **Nov 2024** | Windsurf (Codeium) | Codeium | First self-described "agentic IDE"; AI flows combining copilot and agent patterns | First IDE built from the ground up around AI agents, not just autocomplete. The AI doesn't just suggest code -- it plans, executes multi-file changes, and iterates. |
| **Dec 2024** | Gemini 2.0 Flash | Google | Agentic AI capabilities; multimodal output (images + text + audio); Project Mariner browser agent | Google's "agentic era" model -- not just answering questions but taking actions. Outperformed Gemini 1.5 Pro at twice the speed. Introduced Project Mariner for autonomous web browsing. |
| **Dec 2024** | OpenAI o3 (announced) | OpenAI | 87.5% on ARC-AGI (high compute); massive jump in novel task adaptation | Scored 87.5% on the benchmark designed to test general intelligence -- a task where GPT-4o scored just 5%. Sparked serious debate about whether AI was approaching general reasoning ability. |
| **Dec 2024** | Google Willow quantum chip | Google | Quantum error correction breakthrough; computation in 5 min that would take a supercomputer 10 septillion years | Google's 105-qubit chip solved a 30-year challenge in quantum error correction, showing exponential error reduction as qubits scale up. |
| **Dec 2024** | Sora (Turbo) | OpenAI | Text-to-video generation; up to 20 seconds at 1080p | Type a description, get a photorealistic video. Could generate complex scenes with accurate physics, multiple characters, and specific camera movements. |
| **Jan 2025** | OpenAI Operator | OpenAI | Autonomous web browsing agent; fills forms, places orders, books reservations | AI that uses a web browser like a human -- it can shop online, book travel, fill out forms, and handle repetitive web tasks autonomously. |
| **Feb 2025** | OpenAI Deep Research | OpenAI | Autonomous multi-step web research producing cited reports (5-30 min per query) | An AI research analyst. Give it a question and it spends up to 30 minutes autonomously browsing hundreds of sources, then produces a fully cited research report. |
| **Feb 2025** | Claude 3.7 Sonnet + Claude Code | Anthropic | First hybrid reasoning model (instant or extended thinking); agentic CLI coding tool | First model that lets you toggle between instant answers and deep step-by-step reasoning. Claude Code launched alongside it as a terminal-based autonomous coding agent. |
| **Feb 2025** | GitHub Copilot Agent Mode | GitHub/Microsoft | Multi-file agentic editing; autonomous code changes across entire projects | Copilot evolved from suggesting single lines to autonomously editing multiple files, planning changes, and running tests -- right inside VS Code. |
| **Mar 2025** | Gemini 2.5 Pro | Google | #1 on LMArena and WebDev Arena; 86.7% AIME 2025 math; 1M token context with thinking | Google's best reasoning model. Topped human preference rankings. Could build full web apps, solve competition-level math, and process an hour of video in one prompt. |
| **Apr 2025** | GPT-4.1 | OpenAI | 1M token context; 54.6% SWE-bench; specialized for coding with minimal extraneous edits | OpenAI's coding specialist. One million token context window meant it could ingest entire codebases. Reduced unnecessary code changes from 9% to 2%. |
| **Apr 2025** | OpenAI o3 + o4-mini (released) | OpenAI | PhD-level science (83.3% GPQA Diamond); visual chain-of-thought reasoning | Full release of o3 reasoning model. First model to integrate images directly into its chain of thought -- it could reason visually, not just with text. |
| **Apr 2025** | Codex CLI | OpenAI | Open-source terminal coding agent (Apache 2.0); local execution with o3/o4-mini | OpenAI's answer to Claude Code -- an open-source, terminal-based coding agent that runs locally. Developers could use frontier reasoning models to write and edit code from their terminal. |
| **May 2025** | Claude Opus 4 + Sonnet 4 | Anthropic | Best coding model (72.5% SWE-bench); sustained multi-hour autonomous work; hybrid instant/thinking modes | Claude Opus 4 could work continuously for hours on complex coding tasks spanning thousands of steps. Both models could use tools (web search, etc.) during their reasoning process. |
| **May 2025** | GitHub Copilot Coding Agent | GitHub/Microsoft | Asynchronous AI agent embedded in GitHub; assigns tasks via issues | AI that works like a junior developer on your team. Assign it a GitHub issue, and it autonomously writes code, creates a PR, and runs tests -- while you do other work. |
| **Aug 2025** | GPT-5 | OpenAI | 94.6% AIME 2025 math; 74.9% SWE-bench; state-of-the-art in health, coding, multimodal understanding | OpenAI's next-generation flagship. Near-perfect on competition math. Set new records across coding, health questions, and visual understanding. Described as the biggest single leap since GPT-4. |
| **Aug 2025** | Google Jules (GA) | Google | Asynchronous AI coding agent integrated with GitHub; powered by Gemini 2.5 Pro | Google's answer to GitHub Copilot's coding agent. Runs asynchronously in the cloud, cloning repos, fixing bugs, and submitting PRs while developers focus elsewhere. Free tier available. |
| **Sep 2025** | Claude Sonnet 4.5 + Claude Code 2.0 | Anthropic | 77.2% SWE-bench; 30+ hour autonomous coding sessions; VS Code extension; 0% error rate on code editing | The AI coding ceiling kept rising. Sonnet 4.5 could work autonomously for over 30 hours and achieved a 0% error rate on Anthropic's internal code editing benchmark. Claude Code gained a native VS Code extension. |
| **Oct 2025** | Cursor 2.0 + Composer | Cursor (Anysphere) | Purpose-built coding model; multi-agent parallel architecture; agent-centric interface | The fastest software product ever to $100M ARR reinvented itself with its own model and a multi-agent architecture where multiple AI agents work on different parts of a codebase simultaneously. |
| **Nov 2025** | Claude Opus 4.5 | Anthropic | Improved coding and business/workplace tasks (spreadsheets, analysis) | Anthropic's most powerful model, focused on production coding and complex workplace tasks like financial analysis and document processing. |
| **Feb 2026** | Claude Opus 4.6 | Anthropic | Latest frontier model (current) | The most recent Claude release, continuing the cadence of iterative capability improvements. |
| **Feb 2026** | GPT-5.2 theoretical physics | OpenAI | Derived new result in theoretical physics; first AI original discovery in the field | Derived a formula for single-minus gluon tree amplitudes via 12-hour scaffolded reasoning. Co-authored with researchers from IAS, Vanderbilt, Cambridge, Harvard. |

---

## Key Narrative Arcs for Chart 3

1. **Chat to multimodal** (Mar 2023 - May 2024): GPT-4 text-only, then vision in Sep 2023, then real-time voice/video with GPT-4o in May 2024.

2. **Autocomplete to autonomous agents** (2023-2025): GitHub Copilot line suggestions, then Devin demo (Mar 2024), then Claude Computer Use (Oct 2024), then full terminal agents (Claude Code Feb 2025, Codex CLI Apr 2025), then async agents that work while you sleep (GitHub Copilot Agent May 2025, Jules Aug 2025).

3. **The reasoning revolution** (Sep 2024 - Apr 2025): OpenAI o1 introduced "thinking" models, Claude 3.7 Sonnet introduced hybrid reasoning, and o3/Gemini 2.5 Pro pushed reasoning benchmarks to PhD levels.

4. **The "smaller model beats the flagship" pattern**: Claude 3.5 Sonnet beating Claude 3 Opus (Jun 2024), Gemini 2.0 Flash beating 1.5 Pro (Dec 2024) -- showing that raw model size was no longer the only path to better performance.

5. **AI earns scientific legitimacy**: AlphaFold Nobel Prize (Oct 2024), GPT-5.2 contributing original theoretical physics (Feb 2026).

---

## Sources

- [OpenAI GPT-4 SAT scores - CNBC](https://www.cnbc.com/2023/03/14/openai-announces-gpt-4-says-beats-90percent-of-humans-on-sat.html)
- [GPT-4 Passes the Bar Exam - IIT](https://www.iit.edu/news/gpt-4-passes-bar-exam)
- [GPT-4o announcement - OpenAI](https://openai.com/index/hello-gpt-4o/)
- [OpenAI o1 Wikipedia](https://en.wikipedia.org/wiki/OpenAI_o1)
- [OpenAI o3 Wikipedia](https://en.wikipedia.org/wiki/OpenAI_o3)
- [Claude model history - Wikipedia](https://en.wikipedia.org/wiki/Claude_(language_model))
- [Claude 3 family announcement - Anthropic](https://www.anthropic.com/news/claude-3-family)
- [Claude 3.5 Sonnet introduction - Anthropic](https://www.anthropic.com/news/claude-3-5-sonnet)
- [Computer Use announcement - Anthropic](https://www.anthropic.com/news/3-5-models-and-computer-use)
- [Claude 3.7 Sonnet and Claude Code - Anthropic](https://www.anthropic.com/news/claude-3-7-sonnet)
- [Introducing Claude 4 - Anthropic](https://www.anthropic.com/news/claude-4)
- [Claude Sonnet 4.5 - Anthropic](https://www.anthropic.com/news/claude-sonnet-4-5)
- [Claude Opus 4.5 - Anthropic](https://www.anthropic.com/news/claude-opus-4-5)
- [Gemini 2.5 Pro - Google Blog](https://blog.google/innovation-and-ai/models-and-research/google-deepmind/gemini-model-thinking-updates-march-2025/)
- [Gemini 2.0 announcement - Google Blog](https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/)
- [Gemini 1.0 Wikipedia](https://en.wikipedia.org/wiki/Gemini_(language_model))
- [GPT-4 Turbo DevDay - OpenAI](https://openai.com/index/new-models-and-developer-products-announced-at-devday/)
- [GPT-4V system card - OpenAI](https://openai.com/index/gpt-4v-system-card/)
- [GPT-4.1 introduction - OpenAI](https://openai.com/index/gpt-4-1/)
- [GPT-5 introduction - OpenAI](https://openai.com/index/introducing-gpt-5/)
- [o3 ARC-AGI breakthrough - ARC Prize](https://arcprize.org/blog/oai-o3-pub-breakthrough)
- [OpenAI Operator - OpenAI](https://openai.com/index/introducing-operator/)
- [OpenAI Deep Research - OpenAI](https://openai.com/index/introducing-deep-research/)
- [Codex CLI - OpenAI](https://openai.com/index/introducing-codex/)
- [AlphaFold Nobel Prize - Google DeepMind](https://deepmind.google/blog/demis-hassabis-john-jumper-awarded-nobel-prize-in-chemistry/)
- [Google Willow quantum chip - Google Blog](https://blog.google/innovation-and-ai/technology/research/google-willow-quantum-chip/)
- [Sora launch - OpenAI](https://openai.com/index/sora-is-here/)
- [Devin announcement - Cognition](https://cognition.ai/blog/introducing-devin)
- [MCP - Wikipedia](https://en.wikipedia.org/wiki/Model_Context_Protocol)
- [Windsurf launch - Windsurf](https://windsurf.com/blog/windsurf-launch)
- [Cursor Wikipedia](https://en.wikipedia.org/wiki/Cursor_(code_editor))
- [GitHub Copilot Agent Mode - GitHub](https://github.com/newsroom/press-releases/agent-mode)
- [GitHub Copilot Coding Agent - GitHub](https://github.com/newsroom/press-releases/coding-agent-for-github-copilot)
- [Jules GA - Google Blog](https://blog.google/technology/google-labs/jules-now-available/)
- [ChatGPT Plugins - OpenAI](https://openai.com/index/chatgpt-plugins/)
- [OpenAI GPT-5.2 physics - OpenAI](https://openai.com/index/new-result-theoretical-physics/)
